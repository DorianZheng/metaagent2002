# LLM Provider Configuration for MetaAgent 2002
# Copy this file to .env and update with your actual API keys

# ===== OpenAI Configuration =====
# Get your API key at: https://platform.openai.com/api-keys
# Supported models: gpt-4, gpt-4-turbo, gpt-3.5-turbo
OPENAI_API_KEY=sk-your-openai-key-here
OPENAI_BASE_URL=https://api.openai.com/v1

# ===== Anthropic Configuration =====
# Get your API key at: https://console.anthropic.com/settings/keys
# Supported models: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here
ANTHROPIC_BASE_URL=https://api.anthropic.com/v1

# ===== Google AI Configuration =====
# Get your API key at: https://makersuite.google.com/app/apikey
# Supported models: gemini-pro, gemini-pro-vision
# Note: Google AI SDK expects GOOGLE_GENERATIVE_AI_API_KEY
GOOGLE_GENERATIVE_AI_API_KEY=your-google-ai-key-here
GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1beta

# ===== Kimi Configuration =====
# Get your API key at: https://platform.moonshot.cn
# Models are automatically discovered from API (includes k2, vision, and latest models)
KIMI_API_KEY=your-kimi-api-key-here
KIMI_BASE_URL=https://api.moonshot.cn/v1

# ===== Ollama Configuration (Local Models) =====
# Install Ollama from: https://ollama.ai
# Start with: ollama serve
# Pull models with: ollama pull llama2
# Supported models: llama2, codellama, mistral (depends on what you've pulled)
OLLAMA_BASE_URL=http://localhost:11434

# ===== Server Configuration =====
# Port for the Express server (default: 3001)
PORT=3001

# ===== Setup Instructions =====
# 1. Copy this file to .env
# 2. Add your API keys for the providers you want to use
# 3. Remove the comment # from the providers you want to enable
# 4. Restart the server: npm run dev
# 5. Use the Settings panel in the UI to select your preferred provider and model

# ===== Provider-Specific Notes =====
# OpenAI: Uses OPENAI_API_KEY and OPENAI_BASE_URL
# Anthropic: Uses ANTHROPIC_API_KEY and ANTHROPIC_BASE_URL
# Google AI: Uses GOOGLE_GENERATIVE_AI_API_KEY and GOOGLE_BASE_URL
# Kimi: Uses KIMI_API_KEY and KIMI_BASE_URL
# Ollama: Uses OLLAMA_BASE_URL (no API key required)

# ===== Architecture Simplification =====
# This version uses standard AI SDK environment variable names directly.
# The server reads these variables directly and passes them to AI SDK.

# ===== Troubleshooting =====
# - If you get "API key missing" errors, check your .env file and restart the server
# - If you get "Forbidden" errors, verify your API key is valid and has sufficient credits
# - Check server logs for detailed request/response information
# - The app will fall back to built-in templates if all API calls fail
